---
title: "Exploratory_Analysis"
output: html_document
---

```{r include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Exploratory Analysis

```{r include = FALSE}
#Customize ggplot theme
theme_set(theme_minimal())
theme_update(axis.text.x = element_text(angle = 60, hjust = 1))
theme_update(plot.title = element_text(color="#666666", face="bold", size=22, hjust=0))
theme_update(axis.title = element_text(color="#666666", face="bold", size=18))
theme_update(plot.title = element_text(hjust = 0.5))
```


## Ex Post Facto
> Ex Post Facto variables that are generated after the start of the project. These are interesting to examine and can provide valuable insight into Kickstarter, however, they are not appropriate to use in our predictive models as they are pseudo outcome variables. Some, such as `comments`, can provide direction to a project creator on what to do mid-project to increase their cahnce of funding. 

### `backers_count`
> `backers_count` is a powerful predictor of project funding. We can see that the distribution resembles a logistic function. We found it surprising that even at the top 5% of `backers_count` there are still projects that are not funded. We hypothesize that these projects have an extremely large `goal`.

```{r echo = FALSE}
df_backers = data.frame(funded = df_engr$funded, backers_count = df_engr$backers_count)
df_backers$df_bc_20 = cut(df_backers$backers_count, breaks = unique(quantile(df_backers$backers_count, seq(0, 1, by = .05))), include.lowest = TRUE)

df_backers %>% 
  group_by(df_bc_20) %>%
  summarise(avg_funded = mean(funded)) %>%
  ggplot(aes(x = df_bc_20, y = avg_funded)) +
    geom_bar(stat="identity", fill = "#332288") +
    labs(title = "Funding By Backers",
         x="Number of Backers",
         y="Chance of Funding")
  
#Clean Up
rm(df_backers)
```

***
### `comments_count`
> The vast majority of projects received fewer than 20 comments. Chance of Funding increases substantially as comments increases. The most notable feature is receiving as few as two comments can increase Chance of Funding by 30%+.  We hypothesize that a good project has a causal relationship with more comments. The correlation is enough to advise any creator to make a concerted effort to start a conversation in the comments section of their project. 

```{r echo = FALSE}
df_commments = data.frame(funded = df_engr$funded, comments_count = db_cleaned$comments_count)
df_commments$df_cc_20 = cut(df_commments$comments_count, breaks = unique(quantile(df_commments$comments_count, seq(0, 1, by = .05))), include.lowest = TRUE)

df_commments %>% 
  group_by(df_cc_20) %>%
  summarise(avg_funded = mean(funded)) %>%
  ggplot(aes(x = df_cc_20, y = avg_funded)) +
  geom_bar(stat="identity", fill = "#332288") +
  labs(title = "Funding By Comments",
       x="Number of Comments",
       y="Chance of Funding")

rm(df_commments)
```

***
### `updates_count`
> Another solid indicator of funding `updates_count`. Just as with the other ex post facto variables, the causality is likely reversed as creators are probably more willing to update a project that is getting traction. Given the continued improvements throughout the deciles, it is surely worth regularly providing updates for your project to finish off the funding, or possibly move well past the 100% funded mark. 

```{r echo = FALSE}
df_updates = data.frame(funded = df_engr$funded, updates_count = df_engr$updates_count)
df_updates$uc_10 = cut(df_updates$updates_count, breaks = unique(quantile(df_updates$updates_count, seq(0, 1, by = .1))), include.lowest = TRUE)

df_updates %>% 
  group_by(uc_10) %>%
  summarise(avg_funded = mean(funded)) %>%
  ggplot(aes(x = uc_10, y = avg_funded)) +
    geom_bar(stat="identity", fill = "#332288") +
    labs(title = "Funding By Updates",
         x="Number of Updates",
         y="Chance of Funding")
  
#Clean Up
rm(df_updates)
```

***
### `spotlight`
> We were surprised to find a variable with 100% predictive power occurring in over 20,000 projects. We dug deeper and found that `spotlight` denotes projects to be featured on Kickstarter's recently funded page! [Kickstarter Spotlight](https://www.kickstarter.com/spotlight)

```{r echo=FALSE}
df_engr %>%
  group_by(spotlight) %>%
    summarise(n(), mean(funded)) %>%
  ungroup(spotlight)
```

## Day Zero
Day Zero variables are any which can be observed and/or controlled at the start of the project. These are the most important for our predictive models as they allow us to predict a project's funding before any Kickstarter activity. 

### `goal`
One of the most obvious, and ultimately significant predicters is `goal`. It shows a clear downward trend in funding success as the amount increases. While this is intuitive, it is worth noting that it does not appear linear. For this reason, we used the quantile function to account for this distribution. 

```{r echo = FALSE}
df_engr %>% 
  ggplot(aes(x = goal_20, y = funded)) +
  stat_summary(geom = "bar", fun.y = "mean", fill = "#332288") +
    labs(
    title = "Funding By Goal",
    x="Goal Amount", 
    y="Chance of Funding")

```


### `category`

Some categories never fail in this dataset (only considered if n > 50):
* design/product design (1098 projects)
* film & video/documentary (2202 projects)
* film & video/shorts (3513 projects)
* games/tabletop games (1064 projects)  

Most successful parent categories (only considered if n > 100):
* 7 1,725 projects 81.2% successful
* 11 12,087 projects 65.2% successful
* 14 14,635 projects 59.2% successful  

Least successful parent categories (only considered if n > 100):
* 18 8,725 projects 39.7% successful
* 16 1,638 projects 46.2% successful
* 12 4,125 projects 46.9% successful  
  
```{r echo = FALSE}
# By main category
# 15 unique categories

df_engr %>%
  group_by(category) %>%
  summarise(count = n(), 
            success_rate = round(mean(funded)*100, 2), 
            avg_goal = mean(goal, na.rm = TRUE), 
            #min(percent_funded, na.rm = TRUE), 
            med_perc_funded = median(percent_funded, na.rm = TRUE), 
            #max(percent_funded, na.rm = TRUE),
            avg_perc_funded = mean(percent_funded, na.rm = TRUE), 
            avg_backer_count = mean(backers_count), 
            #min(backers_count), 
            med_backer_count = median(backers_count), 
            #max(backers_count), 
            avg_contribution = mean(avg_contribution, na.rm = TRUE), 
            #min(avg_contribution, na.rm = TRUE), 
            med_contribution = median(avg_contribution, na.rm = TRUE)) %>%
            #max(avg_contribution, na.rm = TRUE)) %>%
  arrange(desc(count)) %>%
  ungroup(category)

#Logit
#Some categories significant
#logit_category <- glm(funded ~ category, data = df_engr, family = binomial(link='logit'))
#summary(logit_category)
#Clean up
#rm(logit_category)
```

#### Frequency by `category`
The distribution of projects by category shows Kickstarter has an intense focus on creative projects. We hypothesize that the minimal appearance of some categories suggests that Kickstarter's classification system tends to favor large, general grouping. It may also be arbitrary in some instances as many `dance` and `photography` projects could readily be placed in `art`.

```{r echo = FALSE}
df_engr %>% 
  group_by(category) %>%
  summarise(count = n()) %>%
  ggplot(aes(x = reorder(category, -count), y = count)) +
  geom_bar(stat="identity", fill = "#332288") +
  labs(title = "Frequency By Category",
       x="Project Category",
       y="Number of Projects")

```

#### Funding by `category`
The chance of funding does not follow a similar pattern to the category frequency distribution. In fact, the sparsely populated categories have near perfect funding rates. Further investigation into these anomalies, such as exploring correlation to variables such as `spotlight` may reveal a selection bias for obscure classification. 

```{r echo = FALSE}
df_engr %>% 
  group_by(category) %>%
  summarise(count = n(), avg_funded = round(mean(funded)*100, 2)) %>%
  ggplot(aes(x = reorder(category, -count), y = avg_funded)) +
  geom_bar(stat="identity", fill = "#332288") +
  labs(title = "Funding By Category",
       x="Project Category",
       y="Chance of Funding")
```

### 'launched_at'
The number of projects increased exponentially 2009 - 2012 and seemed to be increasing more gradually after 2012. We only collected data through December of 2013 and anticipate continued growth for subsequent years.

```{r echo=FALSE}
df_engr %>% 
  ggplot(aes(x = yr_launched, y = funded)) +
  geom_bar(stat="identity", fill = "#332288") +
    labs(
    title = "Project Launch By Year",
    x="Year", 
    y="Projects Launched")
```

We explored fundy by `mo_launched` to see if seasonality impacts Kickstarter. The most dramatic dips occur in May and December. This is consistent with our understanding of financial markets in general... they slow down early summer and have much lower volume around the holiday season.

```{r echo=FALSE}
df_engr %>% 
  ggplot(aes(x = mo_launched, y = funded)) +
  stat_summary(geom = "bar", fun.y = "mean", fill = "#332288") +
    labs(
    title = "Funding By Month Launched",
    x="Month Launched", 
    y="Chance of Funding")

```

### `country`
The majority of projects are based in the United States. Domestic projects have a success rate about 7% higher than international projects. We believe two factors drive this difference. First, Kickstarter is a U.S. based company and will, therefore, better meet the needs of its customers. Secondly, crowdfunding requires a critical mass of people to support a project ecosystem. As backer are most likely to fund projects in their country, any new regional expansions will have lower success rates while the critical mass develops.  

```{r echo=FALSE}
df_country <- data.frame(funded = df_engr$funded, country = db_cleaned$country, usa = df_engr$usa)

df_country %>%
  group_by(country) %>%
    summarise(count = n(), funded_rate = mean(funded)) %>%
  arrange(desc(count)) %>%
  ungroup(country)

summary(lm(funded ~ usa, data = df_country))

#Clean up
rm(df_country)
```


### `photo_key`
There are very few projects that do not at least have a photo. Consequently, a t-test shows no significant difference between having and not having a photo. This is probably not because photos don't matter, but rather because the sample with no photo is too small to have statistical power.

```{r echo=FALSE}
df_engr %>%
  group_by(photo_key) %>%
    summarise(n(), mean(funded)) %>%
  ungroup(photo_key)

t.test(funded ~ photo_key, data = df_engr)
```


### `video_status`
We hypothesized that `video_status` would be a powerful predictor as it is a proxy for whether or not the project has a video. We can see that the t-test 'video_status` to statistically significantly impact the success of the project. 

```{r}
df_engr %>%
  group_by(video_status) %>%
    summarise(n(), mean(funded)) %>%
  ungroup(video_status)

t.test(funded ~ video_status, data = df_engr)
```

##Social media connectedness variables
Social media shows an impact. Facebook seems to be the strongest and Youtube has a negative coefecient. Our hypothesis is that Facebook and Twitter may be used for promotion, while creators focusing on YouTube may over rely on their product content. Yet the most successfull creators have all three, which supports that YouTube is effective when paired with a comprehensive social media campaign.

```{r}
#facebook
df_engr %>%
  group_by(facebook) %>%
    summarise(n(), mean(funded)) %>%
  ungroup(facebook)

#twiter
df_engr %>%
  group_by(twitter) %>%
    summarise(n(), mean(funded)) %>%
  ungroup(twitter)

#youtube
df_engr %>%
  group_by(youtube) %>%
    summarise(n(), mean(funded)) %>%
  ungroup(youtube)

#social_media_count
df_engr %>%
  group_by(social_media_count) %>%
    summarise(n(), mean(funded)) %>%
  ungroup(social_media_count)

df_engr %>% 
  ggplot(aes(x = social_media_count, y = funded)) +
  stat_summary(geom = "bar", fun.y = "mean", fill = "#332288") +
  labs(title = "Funding By Social Media Count",
       x="Social Media Count",
       y="Chance of Funding")

```

### `campaign_duration`
Interestingly, campaign duration has an inverse relationship to the likelihood of receiving funding; longer campaign are associated with higher failure rates.

```{r echo=FALSE}

df_camp_dur = data.frame(funded = df_engr$funded, campaign_duration = df_engr$campaign_duration)
df_camp_dur$cd_10 = cut(df_camp_dur$campaign_duration, breaks = unique(quantile(df_camp_dur$campaign_duration, seq(0, 1, by = .1))), include.lowest = TRUE)

df_camp_dur %>% 
  group_by(cd_10) %>%
  summarise(avg_funded = mean(funded)) %>%
  ggplot(aes(x = cd_10, y = avg_funded)) +
  geom_bar(stat="identity", fill = "#332288") +
  labs(title = "Funding By Campaign Duration",
       x="Number of Comments",
       y="Chance of Funding")

rm(df_camp_dur)

```

### `description_length`
We believe that a description can have a significant impact on a project's funding. In this projects next steps, we hope to extract more meaningful variables from the text analysis we have conducted. However, even in the most basic form, `description_length` shows a clear trend. It improves the chance of funding and then levels off. This implies that putting in the effort to make a detailed description is worthwhile. However, excessive wordiness and/or novel style descriptions quickly hit diminishing returns. 

```{r echo=FALSE}
df_engr %>% 
  ggplot(aes(x = description_length_10, y = funded)) +
  stat_summary(geom = "bar", fun.y = "mean", fill = "#332288") +
    labs(
    title = "Funding By Description Length",
    x="Length of Description", 
    y="Chance of Funding")
```


### `rewards`

```{r}
df_engr %>% 
  ggplot(aes(x = reward_length_10, y = funded)) +
  stat_summary(geom = "bar", fun.y = "mean", fill = "#332288") +
    labs(
    title = "Funding By Rewards",
    x="Length of Rewards", 
    y="Chance of Funding") + 

```

## Not Fully Explored
More granular location variables would require more cleaning and may produce regional insights. 
* `location_name`
* `location_state`
* `location_type`
* `fx_Rate`
* `profile_blurb`
* `profile_state`


## Rejected
We looked at this, yet did not find them to be predictive:
* `project_id`
* `disable_communicaiton`


```{r}
##$project_id
#A random identifier, cannot easily observe a pattern
range(db_cleaned$project_id)
```

```{r include=FALSE, eval=FALSE}
##$converted_pledged_amount
#Validate hypothesis that $converted_pledged_amount = $fx_rate * $pledged

# fx_rate is the exchange rate to USD
for (i in length(db_cleaned$converted_pledged_amount)) {
  if (db_cleaned$converted_pledged_amount[i] == db_cleaned$fx_rate[i]*db_cleaned$pledged[i]) {
    i = i + 1
  } else {
    print("FALSE")
  }
  print("COMPLETE")
}
```

```{r include=FALSE, eval=FALSE}
##$disable_communication
#This is not a user initiated setting, rather an effect of a project being suspended.

df_filtered_disable_communicaiotn <- db_cleaned %>%
  filter(disable_communication == "True")

df_filtered_state_suspended <- db %>%
  filter(state == "suspended")

rownames(df_filtered_disable_communicaiotn) == rownames(df_filtered_state_suspended)

#Clean Up
rm(df_filtered_disable_communicaiotn)
rm(df_filtered_state_suspended)
```

```{r include=FALSE, eval=FALSE}
###Other Location variables
#These would require a lot of cleaning, and might be valuable for making heat maps. However, they are not condusive to making a prediction.

df_country <- data.frame(funded = df_engr$funded,
                         location_name = db_cleaned$location_name,
                         location_state = db_cleaned$location_state,
                         location_type = db_cleaned$location_type)

df_country %>%
  group_by(location_name) %>%
    summarise(n(), mean(funded)) %>%
  ungroup(location_name)

df_country %>%
  group_by(location_state) %>%
    summarise(n(), mean(funded)) %>% 
  ungroup(location_state)

df_country %>%
  group_by(location_type) %>%
    summarise(n(), mean(funded)) %>%
  ungroup(location_type)

rm(df_country)
```

```{r include=FALSE, eval=FALSE}
##$funded
On average: projects that are funded far exceed their goal amount; the average contribution per backer is higher and there are more backers; and the goal amount tends to be significantly lower.

df_engr %>%
  group_by(funded) %>%
  summarise(n(),
            mean(percent_funded, na.rm = TRUE), 
            mean(avg_contribution, na.rm = TRUE), 
            mean(goal, na.rm = TRUE),
            mean(backers_count), 
            median(backers_count), 
            max(backers_count), 
            mean(avg_contribution, na.rm = TRUE)) %>%
  ungroup(funded)
```

```{r include=FALSE, eval=FALSE}
##$avg_contribution
#Appears to have a skewed normal distribution with a mean of $72.

#mean(df_engr$avg_contribution, na.rm = TRUE)

# Apparently normal distribution
df_filtered_by_avg_contribution <- df_engr %>%
  filter(avg_contribution < 1500)

# Box Plot
boxplot(df_filtered_by_avg_contribution$avg_contribution)

# Histogram
df_filtered_by_avg_contribution %>%
  ggplot() + 
  geom_histogram(aes(x = avg_contribution))

#Clean up
rm(df_filtered_by_avg_contribution)
```


```{r eval=FALSE, include=FALSE}
## Date variables
#Average of 2-20 minutes difference btween deadline and failed_at, successful_at, state_changed_at
#Difference is not meaningful, so remove failed_at, successful_at, state_changed_at
ticktock <- data.frame(db_cleaned$created_at, 
                       db_cleaned$deadline, 
                       db_cleaned$failed_at, 
                       db_cleaned$launched_at, 
                       db_cleaned$state_changed_at, 
                       db_cleaned$successful_at)

ticktock <- mutate(ticktock, 
                   deadline_failed = db_cleaned.deadline - db_cleaned.failed_at,
                   deadline_success = db_cleaned.deadline - db_cleaned.successful_at,
                   deadline_state = db_cleaned.deadline - db_cleaned.state_changed_at)

mean(ticktock$deadline_failed, na.rm = TRUE)
mean(ticktock$deadline_success, na.rm = TRUE)
mean(ticktock$deadline_state)

rm(ticktock)
```