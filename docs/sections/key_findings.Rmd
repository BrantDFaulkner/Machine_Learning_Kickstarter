---
title: "Key Findings"
output: html_document
---

```{r include=FALSE}
#Customize ggplot theme
theme_set(theme_minimal())
theme_update(axis.text.x = element_text(angle = 60, hjust = 1))
theme_update(plot.title = element_text(color="#666666", face="bold", size=22, hjust=0))
theme_update(axis.title = element_text(color="#666666", face="bold", size=18))
theme_update(plot.title = element_text(hjust = 0.5))
```

# Key Findings

## Machine Learning Predictions

> We set out on this project to answer one question, "Can we use machine learning to predict which Kickstarter projects will get funded?" As it turns out, we can! 
__Using relatively simple machine learning techniques and feature engineering, we raised our baseline accuracy from 56% to 
70% (a 25% improvement)!__
First, it is essential to establish a baseline metric for success. Given that in our collected data projects were funded at a rate of 56%, a model in the absolute simplest version would predict that every project was funded and be correct 56% of the time. For our predictions to have any value, we must beat this benchmark.
During our exploratory analysis, we discovered a variable with exciting implications, `staff pick`. As machine learning applications become more widely used and increase in efficacy, often the benchmark is, "Can it do better than a human?" `staff_pick` serves as a proxy for the best human judgment has to offer with 84% receiving funding.
You can check them out: [Kickstarter - Projects We Love](https://www.kickstarter.com/discover/recommended)

```{r}
df_engr %>%
  group_by(staff_pick) %>%
    summarise(n(), mean(funded)) %>% 
  ungroup(staff_pick)
```

> Kickstarter staff clearly has an eye for promising projects. However, predicting project success anywhere near this rate is likely impossible. Projects fortunate enough to be a `staff_pick` get prominently featured on the website, newsletters, and blogs. We do not doubt that such promotion materially effects the chance a project is funded. 

> Scoping our target prediction accuracy range to 56-84%, we began construction models.  We built a LASSO Regression and Decision Tree models. Incorporating variables about the campaign such as `goal`, `rewards`, `category`, and `usa` along with information from the creator's profile such as `social_media_count` both models achieved an accuracy rate of ~70%--right in the middle of our target range. 


***
## `percent_funded`
> Percent funded is defined as the amount pledged by the end of a campaign divided by the goal amount specified at the beginning of the campaign. Our data shows an immense range, from projects that received no funding at all to one that received four million perecent. 

> Initially, we thought percent funded would be a good continuous outcome variable for predictive modeling. It is more precise than binary classification, which required selecting a somewhat arbitrary decision threshold. However, plotting the histogram shows that the data has a non-normal distribution. The distribution shows that most projects over ~75% of their goal wind up being successful. Because of this pattern, `percent_funded` was unsuitable for predictive modeling. This distribution also prevented conducting any natural experiemnts, such as regression discontinuity, to determine differences between barely-failed and barely-successful projects.

> Further online research showed that there may be outside manipulation happening due to Kickstarter promotions of projects that are near their goals. In addition, personal donations by the creators and/or creators personal connections may play a role in generating the observed distribution.

```{r echo=FALSE, message=FALSE, warning=FALSE}

df_filtered_by_percent_funded <- df_engr %>%
  filter(!is.na(percent_funded) & percent_funded <= 400)

# Non-normal distribution
df_filtered_by_percent_funded %>% 
  ggplot(aes(x = percent_funded)) + 
  geom_histogram(fill = "#332288") +
  labs(title = "Histogram of Percent Funded", x = "Pledged/Goal (%)", y = "Number of Projects")

#Clean up
rm(df_filtered_by_percent_funded)
```

***
## In-progress Causality
> During our exploratory analysis, we discovered many interesting variables. However, it quickly became apparent that our project as a complicated confounding variable, the point in time the project was observed. Our data is collected from the project as it exists now--completed.

> The significance of this is that as we build our models to predict the outcome of a project at its launch, we have access to information from the "future," beyond just the outcome variable of `funded`. Examples include `comments_count`, `updates count`, and whether a project gets featured on the almost funded page. We will use `comments_count` to dive a bit deeper.

```{r echo = FALSE}
df_commments = data.frame(funded = df_engr$funded, comments_count = db_cleaned$comments_count)
df_commments$df_cc_20 = cut(df_commments$comments_count, breaks = unique(quantile(df_commments$comments_count, seq(0, 1, by = .05))), include.lowest = TRUE)

df_commments %>% 
  group_by(df_cc_20) %>%
  summarise(avg_funded = mean(funded)) %>%
  ggplot(aes(x = df_cc_20, y = avg_funded)) +
  geom_bar(stat="identity", fill = "#332288") +
  labs(title = "Funding By Comments",
       x="Number of Comments",
       y="Chance of Funding")

rm(df_commments)
```

> We can see an obvious correlation, as `comments_count` increases so does its chance of funding. Unsurprisingly (this is data analytics after all) we find ourselves wrestling with questions of causation. "Do comments cause a project to get funded?" "Or, do great projects that are destined for funding prone to receiving more comments?" 

> Answering this question would require tracking projects over time while they are active and performing controlled experiments. For example, we could build two virtually identical projects and begin seeding the comments of only one, allowing us to identify the causal impact of seeding a project's comment section.

> Luckily, we don't have to validate every hypothesis with statistical rigor to begin making business decisions. Our intuition tells us that the impact of `comments_count` is surely a mixture of causality. We can, therefore, recommend to creators that in addition to designing a compelling project, find a backer or two who are passionate about your project and encourage them to start a discussion on the project page. It might be just what you need to get tip the scales in your favor.
